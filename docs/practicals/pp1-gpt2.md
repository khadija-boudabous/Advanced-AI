# PP1: GPT-2

## Objective

In this practical, you will explore the GPT-2 architecture â€” understanding tokenization, transformer blocks, and text generation.

## Prerequisites

- Python 3.10+
- PyTorch
- Hugging Face `transformers`

## Sections

### 1. Tokenization

*Coming soon.*

### 2. Model Architecture

*Coming soon.*

### 3. Text Generation

*Coming soon.*

### 4. Exercises

*Coming soon.*
